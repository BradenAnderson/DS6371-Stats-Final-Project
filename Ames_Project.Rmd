---
title: "Ames_Project"
author: "Braden Anderson and Rayon Morris"
date: "12/2/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

source("./Functions.R")
```


```{r}
df <- read.csv("./train.csv")
head(df)

```
```{r}

# Filter dataframe such that it only includes rows where the neighborhood column
# is one of the neighborhoods we are interested in for the part 1 analysis.

# Neighborhoods that Century 21 Ames real estate sells in
interesting_neighborhoods <- c("NAmes", "Edwards", "BrkSide")

# Create a new dataframe that only contains the neighborhoods Centry 21 Ames sells in
century_df <- df[(df[,"Neighborhood"] %in% interesting_neighborhoods), ]

# Verify the new dataframe only contains the neighborhoods: NAmes, Edwards, and BrkSide
unique(century_df[,"Neighborhood"])

```

```{r}

df[,"Neighborhood"] <- factor(df[,"Neighborhood"])
century_df[,"Neighborhood"] <- factor(century_df[,"Neighborhood"])

```

```{r}

# NOTES AND PART 1 OUTLINE:

# 1) Equal Lines Model <-- Single regression line for all neighborhoods 
# 2) Parallel lines model <-- The neighborhood effects it at constant amount across all values of the response
# 3) Separate lines model <-- The neighborhood effects the slope (interaction terms)

# Statistical slueth page 250: When to Include Interaction Terms
# 1) When a question of interest pertains to interaction (meadowfoam study)
# 2) When good reason exists to suspect interaction
# 3) When interactions are proposed as a more general model for the purpose of examining
#    the goodness of fit for a model without interaction.

# Questions of interest:
# 1) How does the SalePrice of a house relate to the square footage of the house (GrLivArea)?
# 2) Does the relationship between SalePrice and square footage depend on what neighborhood the house is located in?

# STRATEGY FOR QUESTION OF INTEREST #2:
#
# Step 1: Start with the fullest model (separate lines model)
#
# Step 2: Examine the residual plots for the separate lines model to check if the
#         assumptions for an F-test are met. 
#
# Step 3: If assumptions are met, perform a partial F-test for the hypothesis that
#         the interaction terms can be dropped. (i.e. use the separate lines model
#         as the full model and the parallel lines model as the reduced model to check if
#         we can reduce down to using the parallel lines model). A high p-value indicates that
#         the parallel lines model is adequate.
#
# NOTE: Step 3 essentially asks the question, does the relationship between SalePrice and house
#       size change based on what neighborhood you are in? If p-value is high, the slopes can be 
#       the same (parallel lines), and the answer can be: No, the relationship does not change
#       based on neighborhood. If the slopes cannot be the same, the relatioship does change based
#       on neighborhood.
#
# Step 4: If Step 3 showed that the interaction terms can be dropped, we may want to perform
#         another partial F-test for the hypothesis that the intercepts in the parallel lines
#         models are the same (i.e. full model=parallel lines, reduced model=equal lines).
#
# NOTE: Step 4 does not have an entirely logical interpretation in the context of the problem, 
#       because it essentially asks "Does the SalePrice of a house with a square footage of zero
#       change based on what neighborhood you're in?". (A more useful interpretation may be, does the
#       minimum house price change based on what neighborhood you're in, however interpreting this way
#       seems shaky because that is not really what the intercept represents). It must also be noted
#       that attempting to interpret the intercept here is dangerous to begin with, as the minmum
#       house size in the entire dataset is 334 square feet, therefore statements made about houses
#       with square footage below this value require extrapolation, and are therefore dangerous and unlikely
#       to be useful.

```



#Model 1: Separate Lines Model
```{r}

separate_fits <- lm(SalePrice~GrLivArea+
                      relevel(Neighborhood, ref="NAmes")+             # Add intercept adjustment terms
                      relevel(Neighborhood, ref="NAmes"):GrLivArea,   # Add interaction terms (slope adjustments)
                    data=century_df)

summary(separate_fits)
```



```{r}

plot_slr_via_mlr(fit=separate_fits, 
                 df=century_df,
                 model_type="parallel_lines",
                 explanatory_continuous="GrLivArea", 
                 explantory_grouping="Neighborhood",
                 response="SalePrice")

```



# NOTE: ALL CODE BELOW THIS POINT NEEDS UPDATING!
# Model 1: Equal Lines Model
```{r}

fit <- lm(SalePrice~GrLivArea, 
          data=century_df)

summary(fit)
```


# Check Model Assumptions

# Linearity Assumption
```{r}
plot_scatter()

interesting_neighborhoods <- c("NAmes", "Edwards", "BrkSide")

# Basic scatter plot of SalePrice vs GrLivArea
# Neighborhood column filtered to three neighborhoods of interest.
# Points colored based on neighborhood column, 
# Regression line added
plot_scatter(data=century_df, 
             y_var="SalePrice", 
             x_var="GrLivArea", 
             shade_var = "Neighborhood", 
             show_regression=FALSE, 
             reg_table=FALSE,
             identify_obs = c(131, 339)) # Set to TRUE to ID all observations, or a vector for paricular obs
                                         

# Overall the scatter plot shows strong evidence of a linear trend, however there are a couple concerning (outlier) 
# observations (which we have flagged as observation numbers 131 and 339) that should be investigated. 

# Note that these observation numbers correspond to the rows in the century_df dataframe which has been filtered to 
# only contain observations in the three neighborhoods of interest. (Therefore these observation numbers will be different 
# in the full dataset). 

# Also note that these concerning observations are both in the Edwards neighborhood, and are both large 
# homes that had a unusually low sale price. 
```



```{r, fig.height=4, fig.width=8}

plot_residuals(fit, 
               residual_type="regular", 
               plot_zero_hline=TRUE, 
               extreme_thresh_regular=5, 
               flag_extreme_values=TRUE, 
               id_extreme_values=TRUE)

# The majority of the residual plot is a reasonable representation of the ideal "random cloud", indicating
# that the linearity assumption is met for the majority of the data. However as mentioned with the scatterplot,
# we see a couple outlieing observations that violate this assumption. 
```

# Indepdence Assumption
```{r}

# From the residual plot above, do not see any "tracking" in the residuals. Based on how the data was collected
# we do not have a reason to suspect that serial or cluster effects exist. The Independence assumption is always
# difficult to be completely confident in without intimate knowledge of the data collection process, however
# we will proceed with caution as if this assumption is met.

```


# Normality Assumption
```{r}

plot_residual_qq(fit=fit, 
                 residual_type = "regular")


# Based on the QQPlot of the residuals shown below, we see that overall the quantiles of the residuals are
# linearly related to the theoretical quantiles of the normal distribution. That said, we again note that there
# are still the same few observations raising concern as they do not meet the normality assumption. 
# An "S" shape in a residual QQPlot indicates that one of the distributions (the observed or theoretical), has a 
# longer tails than the other. Here we see observation 339, and perhaps 169 and 190 as well being the
# source of some long-tailedness which violates the normality assumption. 
```


```{r}

plot_residual_histogram(fit=fit, 
                        residual_type="regular", 
                        overlay_normal = TRUE, 
                        num_bins=75,
                        normal_linecolor="purple")

# The residual histogram confirms what we see in the residual QQplot. This plot offers another perspective
# but tells the same story; that are a few observations causing some significant skew which violates 
# the normality of errors assumption.
```

```{r}

plot_residuals(fit, 
               residual_type="externally_studentized", 
               plot_zero_hline=TRUE, 
               extreme_thresh_regular=5, 
               flag_extreme_values=TRUE, 
               id_extreme_values=TRUE)

# Lastly, we review the plot of externally studentized residuals in the context of the normality assumption.
# We see that, for the most part, the residuals seem to be normally distributed around zero, and are not
# consistently shifted in either the positive or negative direction which would be indicative of a 
# heavily skewed distribution. This plot does help identify some potential outliers that may not fit the
# normality assumption. In particular, we note that observations 131, 169, 190 and 339 are all more
# than three standard deviations away from zero and therefore may warrant further inspection.
```

# Equal Variance Assumption
```{r}

plot_residuals(fit, 
               residual_type="regular", 
               plot_zero_hline=TRUE, 
               extreme_thresh_regular=5, 
               flag_extreme_values=TRUE, 
               id_extreme_values=TRUE)

# Reviewing the residual plot in the context of the equal variance assumption, we do not see any
# "fanning" or "funnel shaped" pattern in the plot which would clearly indicate of a violation of
# this assumption. Further, the spread of the residuals about zero seems reasonably consistent across
# the range of fitted values for most observations, again with the exception of observations 131 and 339.
# Observations 131 and 339 have rather large residuals, and considering that there are no other
# observations even close to these fitted values it would be rather unusual to observe such large
# residuals in 2 out of 2 samples if they truly were drawn from a population with the same variance
# as the other observations. 

```

# Look for Influential Observations
```{r}

plot_residual_vs_leverage(fit=fit) 

```



# Model 2: Parallel Lines Model
```{r}

# Parallel lines model
parallel_fit <- lm(SalePrice~GrLivArea+
                     relevel(Neighborhood, ref="NAmes"), # Add indicator variables (intercept adjustment terms).
                   data=century_df)

summary(parallel_fit)
```





```{r}


```


```{r}


```


```{r}


```


```{r}


```


```{r}


```


```{r}


```